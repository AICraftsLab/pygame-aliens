{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AICraftsLab/pygame-aliens/blob/main/aliens.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQIGLPDkGhgG",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!apt install swig cmake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XaULfDZDvrC"
      },
      "outputs": [],
      "source": [
        "!pip install stable-baselines3\n",
        "#swig\n",
        "!pip install gymnasium\n",
        "!pip install huggingface_sb3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEKeXQJsQCYm"
      },
      "source": [
        "During the notebook, we'll need to generate a replay video. To do so, with colab, **we need to have a virtual screen to be able to render the environment** (and thus record the frames).\n",
        "\n",
        "Hence the following cell will install virtual screen libraries and create and run a virtual screen ðŸ–¥"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5f2cGkdP-mb",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install -y python3-opengl\n",
        "!apt install ffmpeg\n",
        "!apt install xvfb\n",
        "!pip3 install pyvirtualdisplay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCwBTAwAW9JJ"
      },
      "source": [
        "To make sure the new installed libraries are used, **sometimes it's required to restart the notebook runtime**. The next cell will force the **runtime to crash, so you'll need to connect again and run the code starting from here**. Thanks to this trick, **we will be able to run our virtual screen.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYvkbef7XEMi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BE5JWP5rQIKf"
      },
      "outputs": [],
      "source": [
        "# Virtual display\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/AICraftsLab/pygame-aliens.git"
      ],
      "metadata": {
        "id": "m4_SUDvTahJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cygWLPGsEQ0m"
      },
      "outputs": [],
      "source": [
        "import gymnasium\n",
        "\n",
        "from huggingface_sb3 import load_from_hub, package_to_hub\n",
        "from huggingface_hub import notebook_login # To log to our Hugging Face account to be able to upload models to the Hub.\n",
        "\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.monitor import Monitor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "import aliens_env\n",
        "from itertools import count\n",
        "\n",
        "import torch\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.callbacks import BaseCallback, CheckpointCallback\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
        "\n",
        "\n",
        "# Save normalization stats callback\n",
        "class SaveNormStatsCallback(BaseCallback):\n",
        "    def __init__(self, vec_env: VecNormalize, filename: str = 'vecnormalize.pkl', save_dir: str = './', verbose: int = 1):\n",
        "        super().__init__(verbose)\n",
        "        self.vec_env = vec_env\n",
        "        self.save_dir = save_dir\n",
        "        self.filename = filename\n",
        "\n",
        "    def _init_callback(self) -> None:\n",
        "        # Create folder if needed\n",
        "        if self.save_dir is not None:\n",
        "            os.makedirs(self.save_dir, exist_ok=True)\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        save_path = os.path.join(self.save_dir, self.filename)\n",
        "        self.vec_env.save(save_path)\n",
        "        if self.verbose >= 1:\n",
        "            print(f\"Saving best model normalizing stats to {save_path}\")\n",
        "\n",
        "        return True\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    env_id = 'Aliens'\n",
        "    save_dir = 'run1'\n",
        "    seed = None\n",
        "    tensorboard_log = 'tensorboard_logs'\n",
        "\n",
        "    # For resuming training\n",
        "    is_new_training = True\n",
        "    model_file_path = None\n",
        "    stats_file_path = None\n",
        "\n",
        "    # Save_dir should not exist if is_new_training\n",
        "    os.makedirs(save_dir, exist_ok= not is_new_training)\n",
        "\n",
        "    timesteps = 5e6\n",
        "    num_cpu = 20  # Env nums\n",
        "    vec_env_cls = DummyVecEnv\n",
        "\n",
        "    vec_env = make_vec_env(env_id, n_envs=num_cpu, vec_env_cls=vec_env_cls, seed=seed)\n",
        "\n",
        "    if is_new_training:\n",
        "        vec_env = VecNormalize(vec_env, norm_obs=True, norm_reward=True)\n",
        "    else:\n",
        "        vec_env = VecNormalize.load(stats_file_path, vec_env)\n",
        "\n",
        "    checkpoint_callback = CheckpointCallback(\n",
        "      save_freq=10000,\n",
        "      save_path=save_dir,\n",
        "      name_prefix=\"model\",\n",
        "      save_replay_buffer=False,\n",
        "      save_vecnormalize=True,\n",
        "      verbose=1,\n",
        "    )\n",
        "\n",
        "    if is_new_training:\n",
        "        model = PPO(\"MlpPolicy\", vec_env, verbose=1, tensorboard_log=tensorboard_log)\n",
        "    else:\n",
        "        model = PPO.load(model_file_path, vec_env, verbose=1, tensorboard_log=tensorboard_log)\n",
        "        print('Loaded model:', model_file_path)\n",
        "\n",
        "    reset_num_timesteps = is_new_training\n",
        "    model.learn(total_timesteps=int(timesteps), callback=checkpoint_callback, reset_num_timesteps=reset_num_timesteps, tb_log_name=save_dir)\n",
        "\n",
        "    print('Training complete')\n",
        "    print('Name:', save_dir)\n"
      ],
      "metadata": {
        "id": "S2VfS5lSb7Lx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7vOFlpA_ONz"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "\n",
        "# First, we create our environment called LunarLander-v2\n",
        "env = gym.make(\"LunarLander-v2\")\n",
        "\n",
        "# Then we reset this environment\n",
        "observation, info = env.reset()\n",
        "\n",
        "for _ in range(20):\n",
        "  # Take a random action\n",
        "  action = env.action_space.sample()\n",
        "  print(\"Action taken:\", action)\n",
        "\n",
        "  # Do this action in the environment and get\n",
        "  # next_state, reward, terminated, truncated and info\n",
        "  observation, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "  # If the game is terminated (in our case we land, crashed) or truncated (timeout)\n",
        "  if terminated or truncated:\n",
        "      # Reset the environment\n",
        "      print(\"Environment is reset\")\n",
        "      observation, info = env.reset()\n",
        "\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZiFBBlzxzxY"
      },
      "outputs": [],
      "source": [
        "notebook_login()\n",
        "!git config --global credential.helper store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2E--IJu8JYq"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "\n",
        "from huggingface_sb3 import package_to_hub\n",
        "\n",
        "# PLACE the variables you've just defined two cells above\n",
        "# Define the name of the environment\n",
        "env_id = \"LunarLander-v2\"\n",
        "\n",
        "# TODO: Define the model architecture we used\n",
        "model_architecture = \"PPO\"\n",
        "\n",
        "## Define a repo_id\n",
        "## repo_id is the id of the model repository from the Hugging Face Hub (repo_id = {organization}/{repo_name} for instance ThomasSimonini/ppo-LunarLander-v2\n",
        "## CHANGE WITH YOUR REPO ID\n",
        "repo_id = \"AbdulrazaqAS/ppo-LunarLander-v2\" # Change with your repo id, you can't push with mine ðŸ˜„\n",
        "\n",
        "## Define the commit message\n",
        "commit_message = \"Upload PPO LunarLander-v2 trained agent\"\n",
        "\n",
        "# Create the evaluation env and set the render_mode=\"rgb_array\"\n",
        "eval_env = DummyVecEnv([lambda: gym.make(env_id, render_mode=\"rgb_array\")])\n",
        "\n",
        "# PLACE the package_to_hub function you've just filled here\n",
        "package_to_hub(model=model, # Our trained model\n",
        "               model_name=model_name, # The name of our trained model\n",
        "               model_architecture=model_architecture, # The model architecture we used: in our case PPO\n",
        "               env_id=env_id, # Name of the environment\n",
        "               eval_env=eval_env, # Evaluation Environment\n",
        "               repo_id=repo_id, # id of the model repository from the Hugging Face Hub (repo_id = {organization}/{repo_name} for instance ThomasSimonini/ppo-LunarLander-v2\n",
        "               commit_message=commit_message)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "BqPKw3jt_pG5"
      ],
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "ed7f8024e43d3b8f5ca3c5e1a8151ab4d136b3ecee1e3fd59e0766ccc55e1b10"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}